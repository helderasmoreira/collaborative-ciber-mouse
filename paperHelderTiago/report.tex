\documentclass[oribibl]{llncs}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{textcomp}       % additional symbols using companion encoding TS1
\usepackage{epstopdf}

\title{Collabot}
\subtitle{A Collaborative Robotic Agent for the CiberRato Competition}
\author{HÃ©lder Moreira \and Tiago Babo}
\institute{Faculdade de Engenharia da Universidade do Porto}

%
\begin{document}
\maketitle
\begin{abstract}
This paper discusses the implementation of mapping and communication for a collaborative robotic agent, using the Ciber-Rato Simulation Tools. Navigation and target localization strategies were also implemented in the discussed agent, however those implementations are further explained in the paper \cite{varelaepontes}.
We focused on developing an interesting solution for a maze solver agent and explore the collaboration between robots with similar architectures.
\end{abstract}

\section{Introduction}
Ciber-Rato is a category of the Micro-Rato contest from University of Aveiro.
This category is a competition between small autonomous robots trying to solve mazes. \cite{Lau2002}
In this project, we faced the challenge of developing a collaborative robotic agent architecture using the Simulation Tools created for the Ciber-Rato competition. The agents should be able to solve simple mazes by finding a beacon and returning to their original position, while avoiding obstacles, collisions and dealing with time constraints. Furthermore, in the collaborative competition, the agents are playing in a team of 5 robots, all the robots must meet in the target area and after that return to their original position. The maze is only considered solved when all the mice return to their original position.

At the starting point, the agents have no previous information about the world state, namely the target position, maze's topology and even his or other mice positions. Therefore, a simple reactive robot architecture was not suitable for this problem, so proper communication, mapping, navigation and target localization strategies were be developed in order to maximize the agent's efficiency.

In this paper, first we present the simulation system architecture. Then the agent architecture and design are analysed, mainly focusing in the mapping and communication strategies, since navigation and target localization strategies are further discussed in the paper \cite{varelaepointes}. After that, the results of the developed strategies are discussed. Finally, in the last section, are presented the main conclusions and some possible future developments.

\section{Simulation System Architecture}
To develop this project the Ciber-Rato Simulation Tools, 2012 edition, were chosen as a simulation platform. This platform allows the developers to focus only on the development of an efficient agent algorithm, eliminating the problems and challenges associated with real robots construction by providing a simulation environment that models all the hardware components of the robots and a allows the developed algorithms to be tested\cite{Lau2002}. 

The simulation environment is composed by a Simulator, a Simulation Viewer and Virtual Robots. The first is responsible for modelling all the hardware components of the robots, the maze and ensure that all the execution rules are applied. The Simulation Viewer displays the maze, the robots movements and the remaining execution time. The virtual Robots are detailed in the section bellow.

All the specifications presents in this paper are based on the Ciber-Rato 2011 Rules and Technical Specifications \cite{DepartamentodeElectronica2011}, and only a brief specification is present in here, for a more detailed specification please consult the document mentioned above.

\subsection{Virtual Robots}
The virtual robots have circular bodies and are equipped with sensors, actuators and command buttons. Only the robots' sensors and actuators used by the agent that we developed are mentioned in this section.

\subsubsection{Sensors}\hfill \\
For the developed agent the following sensors were used, from the ones available in the simulation environment: 
\begin{itemize}
  \item[\textbf{Obstacle Sensors}]
  4 proximity sensors, 3 oriented to the front of the robot (left, middle and right sides), and one in the rear. Each sensor has a $60^{\circ}$ aperture angle.
  \item[\textbf{Beacon Sensor}]
  Measures the angular position of the beacon with respect to the robot's frontal axis. The measure ranges from $-180$ to $+180$ degrees, with a resolution of 1 degree.
  \item[\textbf{Bumper}]Active when the robot collides.
  \item[\textbf{Ground Sensor}]
  Active when the robot is completely in target area.
  \item[\textbf{Compass}]
  Positioned in the center of the robot and measures its angular position with respect to
the virtual North ($x$ axis).
  \item[\textbf{GPS}]
  Returns the position of the robot in the arena, with resolution 0.1. It is located in the center of the robot.
\end{itemize}

\subsubsection{Actuators}\hfill \\
The actuators components of the robots used in this project are 2 motors and 1 signalling LED. 
\begin{itemize}
  \item[\textbf{Motors}]
Motors have inertia and noise in order to more closely represent real motors, and the translation or rotation movements can be achieved by applying different power values to each motor.
  \item[\textbf{LED}]
The LED is used to signal that the robot has already found the beacon.
\end{itemize}

\subsubsection{Buttons}\hfill \\
Two buttons, named Start and Stop, are provided in each robot and are used by the simulator to start and interrupt the competition.

\subsection{Arena}
The arena is randomly positioned in the world, which means that the starting coordinates of the robot may differ for every attempt to solve the maze, and has a maximum size of $14\times28$ um.
The arena is populated with obstacles, a target area, and a starting grid. For the same maze different starting grids can also be used. The obstacles within the arena can be higher then the beacon, making it invisible for the beacon sensor.

\subsection{Communication}
Communication between robots can be made by sending appropriate commands, through the Simulator. The other agents will be then responsible for reading the messages in the simulator. However the following constraints are be applied:
\begin{itemize}
 \item Per cycle, a robot can send (broadcast) up to 100 bytes;
 \item Per cycle, a robot can read up to 400 bytes;
 \item Robots can only read messages sent from a maximum of 8 units from its current position;
 \item Obstacles do not interfere with communication;
 \item Latency of 1 cycle for sent messages.
 \end{itemize} 

\section{Agent Architecture}
In this project we faced the challenge of creating a team of 5 robotic agents, playing simultaneously, in the environment provided by the Ciber-Rato Simulation Tools.
The Mice have two specific goals: locate the target area and place all the agents inside that area; return all the robots back to their original position.

In order to achieve that goal our agents must be able to fully operate in an unstructured environment by avoiding obstacles and finding the beacon in a simple to moderately complex map. 
However, at the starting point, the agents have no previous information about the world state, namely the target position, maze's topology and even his or other mice positions. Therefore, a simple reactive robot architecture was not suitable for this problem and so proper communication, mapping, navigation and target localization strategies were be developed in order to maximize the agents efficiency.

The developed agent architecture is composed by 6 different modules and is represented in figure \ref{fig:robot-arch}.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{robot-architecture.png}
  \caption{System architecture.}
  \label{fig:robot-arch}
\end{figure}

Bellow, the description of each module:

\begin{itemize}
  \item[\textbf{Compute Probabilities}]
  lorem ipsum
  \item[\textbf{Communication}]
  lorem ipsum
  \item[\textbf{Path Planning}]
  lorem ipsum
  \item[\textbf{Visualizers}]
  lorem ipsum
  \item[\textbf{Utils}]
  lorem ipsum
\end{itemize}

\subsection{Mapping}

As previously mentioned, the map arena has a maximum size of 14 x 28 um and the simulator has a precision of 0.1 um. Considering that the initial position of the agent is not initial known, it was necessary to quadruplicate the structure where the arena is mapped. Doing this, it is possible to predict the agent movement in any direction. It was also considered the minimum value of precision, resulting in a matrix of 280 x 560 positions. 

Given that the agent has three sensors that allow him to detect, with noise, obstacles in the environment and that is only known that there is an obstacle in a given distance, it is not possible to have completely certainty about the obstacles position. The values provided by the sensors follow an additive white Gaussian noise deviation of 0.1 and they are the inverse to the distance of the closest obstacle detected. In order to minimize this constraint, the arena is mapped using a probabilities matrix. At start, the arena is not yet explored, hence all positions of the matrix have a probability of being an obstacle of 0.5.  

As the agent moves, the probabilities matrix is updated with new values, allowing to visualize and create a close to reality arena representation. To better use the sensor values, the area represented by the read values is divided in three sections.  

\begin{figure}
  \centering
  \includegraphics[scale=.25]{sensorareas.eps}
  \caption{Sensor areas.}
  \label{fig:sensorareas}
\end{figure}

\begin{itemize}
  \item[\textbf{A}]
  The area up to \begin{equation}
     \dfrac{1}{reading + noise}
    \end{equation}
   is marked has having a low probability of being a wall.
  \item[\textbf{B}]
The area up to \begin{equation}
      \dfrac{1}{reading} - wall width
    \end{equation}
   is marked has having a moderate probability of being a wall.
  \item[\textbf{C}]
  The area up to \begin{equation}
      \dfrac{1}{reading} + wall width
    \end{equation}
   is marked has having a high probability of being a wall.
\end{itemize}

Furthermore, when the agent is moving, the positions where he passes have zero probability of being a wall, so they are marked accordingly with that rule. 

As the positions have already a probability value, at every instant \emph{t} the probability of each affected position \emph{(i, j)} - as in, in the sensor area - is updated using the Bayes theorem rule:

 \begin{equation}
     P_{ij}(H|s_n) =   \dfrac{P_{ij}(s_n|H). P_{ij}(H|s_{n-1})}{P_{ij}(s_n|H).P_{ij}(H|s_{n-1})+ P_{ij}(s_n|~H).P_{ij}(~H|s_{n-1})}
\end{equation}

 $P_{ij}(H|s_n)$ is the probability of the \emph{(i,j)} cell being occupied given a certain measure $s_n$.

There are two conditions in order to a cell to be in the sensor area. First, the distance between the center and the given cell has to be less than the inverse of the read value from the sensor. Second, the atan2 value, that represent the angle in radians between the positive x-axis of a plane and the point given by the coordinates (x, y) on it, has to be in the sensor vision angle range. If this two conditions are true, the cell probability is updated using the previous described method.

\section{Results}

In order to evaluate the agent implementation, the developed solution was tested in different maps and multiple times.

\subsection{Mapping}

The results shown that the mapping algorithm can create a good visualization of the world state, without consuming to much resources. The major problem encountered was in mapping corners as rounded - when the agent was far from them. This happens because the sensor area is interpreted has a semi-circular form. 

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{screenmap.png}
  \caption{Mapping example.}
  \label{fig:screenmap}
\end{figure}

As can be seen on figure \ref{fig:screenmap}, this model isn't perfect, but has a good effectiveness. The probabilities matrix is mainly used to calculate the path when returning home, after finding the beacon.

\subsection{Limitations and Benefits}
This reactive architecture includes some limitations, such as:

\begin{itemize}
  \item if the robot is following the beacon and there is an concave obstacle in the way, most of the times, the robot will be stuck around the same place with conflicting orders to follow the beacon and to avoid the obstacle in front. The rule to only follow the beacon on every 50 iterations was developed to try to circumvent this cases and provided promising results;
  \item by not being able to store the world state the robot wanders around the map without knowing if it has already been there, and this can also create cycles, specially if the robot is surrounded by walls and there is only one way out.
\end{itemize}

The benefits of this type of architecture are that the robot is able to quickly react to dynamic changes in the environment, such as the introduction of a new robot in the system, and also able to react to some environment variable that the robot's programmer has not foreseen.

\section{Conclusion}
lorem ipsum

\section{Future Work}
In terms of mapping, it would be possible to improve corners detection, allowing a better arena representation.

\bibliography{report}
\bibliographystyle{splncs}
\end{document}